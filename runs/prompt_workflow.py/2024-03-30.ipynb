{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+----+---------------+-----------------------------------------------------------+--------------+--------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+-----------+\n",
      "|    | model         | messages                                                  |   max_tokens | response                                                                                               | response_usage                                                     |   latency |\n",
      "|----+---------------+-----------------------------------------------------------+--------------+--------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+-----------|\n",
      "|  0 | gpt-3.5-turbo | [{'role': 'user', 'content': 'Tell me a joke.'}]          |           60 | Why couldn't the bicycle stand up by itself? Because it was two tired!                                 | {'completion_tokens': 16, 'prompt_tokens': 12, 'total_tokens': 28} |  0.766431 |\n",
      "|  1 | gpt-3.5-turbo | [{'role': 'user', 'content': 'Is 17077 a prime number?'}] |           60 | No, 17077 is not a prime number. It can be divided by 1, 17077, 59, and 289.                           | {'completion_tokens': 30, 'prompt_tokens': 15, 'total_tokens': 45} |  2.25014  |\n",
      "|  2 | gpt-4         | [{'role': 'user', 'content': 'Tell me a joke.'}]          |           60 | Why don't scientists trust atoms?                                                                      | {'completion_tokens': 13, 'prompt_tokens': 12, 'total_tokens': 25} |  0.526719 |\n",
      "|    |               |                                                           |              |                                                                                                        |                                                                    |           |\n",
      "|    |               |                                                           |              | Because they make up everything!                                                                       |                                                                    |           |\n",
      "|  3 | gpt-4         | [{'role': 'user', 'content': 'Is 17077 a prime number?'}] |           60 | No, 17077 is not a prime number. It can be divided evenly by 1, 7, 11, 77, 221, 1547, 2437, and 17077. | {'completion_tokens': 45, 'prompt_tokens': 15, 'total_tokens': 60} |  1.41454  |\n",
      "+----+---------------+-----------------------------------------------------------+--------------+--------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from prompttools.experiment import OpenAIChatExperiment\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "# import os\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "# Input messages\n",
    "prompts = [\n",
    "    \"Tell me a joke.\",\n",
    "    \"Is 17077 a prime number?\"\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    [{\"role\": \"user\", \"content\": prompts[0]},],\n",
    "    [{\"role\": \"user\", \"content\": prompts[1]},],\n",
    "]\n",
    "\n",
    "models = [\"gpt-3.5-turbo\", \"gpt-4\"]\n",
    "temperatures = [0.0]\n",
    "outputTokenLimit=[60]\n",
    "\n",
    "exp = OpenAIChatExperiment(\n",
    "    model=models,\n",
    "    messages=messages,\n",
    "    temperature=temperatures,\n",
    "    max_tokens=outputTokenLimit\n",
    "    )\n",
    "\n",
    "\n",
    "exp.run()\n",
    "exp.visualize()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
